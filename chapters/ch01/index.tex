\chapter{Pendahuluan}

\pagestyle{plain}

\section{Latar Belakang}

Pengolahan dan analisis data telah menjadi bagian penting dalam berbagai aspek kehidupan modern \cite{vermaBigDataManagement2016}. Organisasi, perusahaan, dan lembaga pemerintah mengandalkan data untuk pengambilan keputusan yang lebih baik, inovasi produk, pengembangan layanan pelanggan, dan banyak aspek lainnya. Seiring dengan meningkatnya volume data yang dihasilkan setiap hari, tantangan utama yang dihadapi adalah bagaimana mengelola dan menganalisis data ini dengan efisien dan cepat \cite{ahmadvandGapproxUsingGallup2019}. Beberapa solusi telah tersedia untuk mengatasi masalah ini. Salah satu solusi yang paling efisien adalah komputasi terdistribusi. 

Komputasi terdistribusi adalah cara untuk mencapai paralelisme dengan menggabungkan beberapa mesin independen yang berbeda \cite{bhattacharyaEvaluatingDistributedComputing2021}. Dalam komputasi terdistribusi, data besar dibagi ke dalam sejumlah \textit{node} atau server yang bekerja bersama-sama untuk mengolahnya. Dua teknologi yang umum digunakan dalam komputasi terdistribusi ini adalah \textit{Apache Hadoop (MapReduce)} dan \textit{Apache Spark.} \textit{Hadoop} dan \textit{Spark} adalah dua \textit{platform} komputasi \textit{big data} yang paling populer dan banyak digunakan di seluruh dunia. \textit{Platform} ini menawarkan berbagai kemampuan untuk mengelola, menyimpan, dan menganalisis data dalam skala besar. Kedua \textit{platform} ini menyediakan berbagai fungsi menggunakan \textit{application programming interface} (API) yang sederhana sehingga dapat memudahkan dalam penggunaan.

\textit{MapReduce} adalah alat yang digunakan untuk komputasi terdistribusi, dirancang khusus untuk menulis, membaca, dan memproses jumlah data yang besar \cite{deanMapReduceSimplifiedData2004}. Pemrosesan data dalam \textit{MapReduce} ini terdiri dari tiga tahap: fase \textit{Map}, fase \textit{Shuffle}, dan fase \textit{Reduce}. Dalam teknik ini, berkas-berkas besar dibagi menjadi beberapa blok kecil dengan ukuran yang sama dan didistribusikan ke seluruh klaster untuk penyimpanan. \textit{MapReduce} dan sistem file terdistribusi (HDFS) adalah bagian inti dari sistem \textit{Hadoop}, sehingga komputasi dan penyimpanan bekerja bersama-sama di seluruh \textit{node} yang membentuk klaster komputer \cite{samadiComparativeStudyHadoop2016}. \textit{Hadoop MapReduce} memerlukan akses ke penyimpanan untuk membaca dan menulis data, sehingga dapat memperlambat proses komputasi, sehingga hadirlah \textit{Spark}.

\textit{Spark}, di sisi lain, menawarkan teknologi \textit{Resilient Distributed Datasets} (RDDs) untuk mendukung proses \textit{Map} dan \textit{Reducing} secara lebih efektif dan cepat \cite{ahmadvandGapproxUsingGallup2019}. \textit{Spark} bukan hanya alternatif \textit{Hadoop}, tetapi juga menyediakan berbagai fungsi, misalnya mendukung \textit{MLib}, \textit{GraphX}, dan \textit{Spark streaming }untuk analisis data besar \cite{zahariaSparkClusterComputing2010}. Spark menggunakan memori untuk menyimpan data sehingga dapat mengurangi siklus baca dan tulis. Perbedaan mendasar ini mengakibatkan menarik untuk melihat perbandingan performa antara keduanya. Salah satu cara untuk membandingkan performa keduanya adalah menggunakan tolok ukur \textit{Hibench}.

Tolok ukur \textit{HiBench} adalah salah satu tolak ukur kinerja yang paling sering digunakan. \textit{HiBench} mencakup sejumlah tugas \textit{benchmarking} yang mencerminkan berbagai jenis pemrosesan data, seperti pengolahan batch, aliran data, \textit{query}, atau pun \textit{machine learning} \cite{huangHiBenchBenchmarkSuite}. Oleh karena itu, \textit{HiBench} adalah alat yang cocok untuk mengukur dan membandingkan kinerja antara \textit{platform Hadoop}dan \textit{Spark} dalam berbagai skenario penggunaan.

Penelitian tentang evaluasi performa \textit{Hadoop} dan \textit{Spark} menggunakan \textit{HiBench} telah beberapa kali dilakukan. Shi et al. \cite{shiClashTitansMapReduce2015} melakukan penelitian dengan dua alat yang dirancang untuk mengukur kinerja \textit{MapReduce} dan \textit{Spark} dalam berbagai skenario beban kerja. Penelitian ini mengevaluasi kinerja dalam pekerjaan \textit{batch} dan iteratif, dengan fokus pada komponen-komponen penting seperti \textit{shuffle}, dan \textit{caching}. Hasil penelitian mereka menunjukkan bahwa \textit{Spark} lebih cepat daripada \textit{MapReduce} dalam beberapa kasus, terutama ketika menangani tugas-tugas pemrosesan data yang lebih kecil. Namun, ketika ukuran data meningkat, \textit{MapReduce} terbukti lebih efisien. Selanjutnya, perbandingan kinerja antara \textit{MapReduce} dan \textit{Spark} juga disorot oleh penelitian Samadi et al. \cite{samadiComparativeStudyHadoop2016}, yang menggunakan delapan tolok ukur dari \textit{HiBench}. Penelitian ini menunjukkan bahwa \textit{Spark} cenderung lebih efisien ketika menangani data dalam jumlah kecil atau saat memproses tugas dalam memori, sementara \textit{MapReduce} lebih sukses ketika beban kerja melibatkan operasi I/O penyimpanan yang intensif. Selain itu, penelitian oleh Satish dan Rohan \cite{gopalaniComparingApacheSpark2015} menyoroti perbandingan kinerja antara \textit{MapReduce} dan \textit{Spark} khususnya dalam konteks algoritma \textit{K-means}. Mereka menemukan bahwa \textit{Spark} dapat mencapai kecepatan hingga tiga kali lipat dibandingkan \textit{MapReduce}, dengan catatan bahwa performa \textit{Spark} sangat bergantung pada ukuran memori yang memadai.

%TODO: Penelitian terdahulu yang berkaitan dengan topik penelitian, 4 minimal
%Jelaskan isi penelitian terdahulu yang mencakup permasalahan yang diselesaikan (dapat terkait dataset ), metode yang digunakan, dan hasil penelitian.

Berdasarkan penelitian sebelumnya, penelitian ini bertujuan untuk menyelidiki perbandingan kinerja antara \textit{Hadoop} dan \textit{Spark} dengan menggunakan tolak ukur \textit{HiBench} dengan studi kasus tertentu. Dengan pemahaman mendalam mengenai kekuatan dan kelemahan masing-masing \textit{platform} dalam berbagai konteks pemrosesan data, organisasi atau peneliti dapat membuat keputusan yang lebih informasional saat memilih \textit{platform} yang paling sesuai dengan kebutuhan mereka. Selain itu, penelitian ini akan dilakukan dengan memanfaatkan Infrastruktur sebagai Layanan (IaaS) yang disediakan oleh \textit{DigitalOcean}, memungkinkan penggunaan sumber daya komputasi dalam skala yang fleksibel dan efisien. Dengan demikian, penelitian ini akan memberikan kontribusi berharga dalam membantu pemangku kepentingan dalam mengoptimalkan pemrosesan data dalam lingkungan komputasi terdistribusi.

%TODO: jelaskan secara singkat terkait cara pendekatan dan metode penelitian yang akan dilakukan. Dapat menjelaskan dataset dan keterbaharuan dalam hal metode yang digunakan.

\section{Rumusan Masalah}
Adapun rumusan masalah dalam penelitian ini adalah sebagai berikut:
\begin{enumerate}
	\item 
	Bagaimana perbandingan kinerja antara \textit{Hadoop} dan \textit{Spark} dalam mode pseudo-distribusi dalam konteks pemrosesan data dalam skala besar dengan menggunakan tolak ukur \textit{HiBench}?
	\item
	Bagaimana kinerja \textit{Hadoop} dan \textit{Spark} ketika diuji menggunakan berbagai beban kerja (\textit{workloads}) yang disediakan oleh \textit{HiBench benchmarks}?
\end{enumerate}

\section{Tujuan}
Penelitian ini memiliki tujuan, yaitu:
	\begin{enumerate}
		\item 
		Untuk membandingkan kinerja antara \textit{Hadoop} dan \textit{Spark} dalam mode pseudo-distribusi saat memproses data dalam skala besar dengan menggunakan tolak ukur \textit{HiBench}.
		\item
		Untuk mengukur kinerja \textit{Hadoop} dan \textit{Spark} ketika diuji menggunakan berbagai beban kerja (workloads) yang disediakan oleh HiBench benchmarks.
	\end{enumerate}

\section{Manfaat}
Hasil dari penelitian ini diharapkan akan memberikan manfaat sebagai berikut:
\begin{enumerate}
	\item 
	Penelitian ini akan memberikan informasi yang berguna bagi organisasi yang sedang mempertimbangkan pemilihan platform \textit{Big Data}, sehingga mereka dapat membuat keputusan yang lebih terinformasi.	
	\item
	Penelitian ini akan membantu dalam memahami lebih dalam kinerja \textit{Hadoop} dan \textit{Spark} dalam berbagai skenario pemrosesan data.
	\item
	Hasil dari penelitian ini dapat menjadi dasar untuk penelitian lebih lanjut dalam pengembangan dan peningkatan platform \textit{Big Data.}
\end{enumerate}

\section{Batasan Masalah}
Penelitian ini memiliki beberapa batasan yang perlu diperhatikan sebagai berikut:
	\begin{enumerate}
		\item 
		Penelitian ini akan fokus pada perbandingan kinerja antara \textit{Hadoop} dan \textit{Spark} dalam mode \textit{pseudo-distributed.}
		\item
		Pengujian kinerja akan menggunakan \textit{HiBench}, sebuah tolok ukur kinerja yang umum digunakan dalam penelitian \textit{Big Data.}
		\item
		Implementasi \textit{Hadoop} dalam lingkungan komputasi awan akan menggunakan salah satu penyedia awan, yaitu \textit{DigitalOcean}.
		\item
		Penelitian ini akan berfokus pada aspek kinerja. Aspek lain seperti keamanan dan administrasi tidak akan dibahas secara rinci.
	\end{enumerate}

%\section{Metodologi}
%
%Tuliskan semua tahapan yang akan dilalui selama pelaksanaan tugas akhir. Tahapan ini spesifik untuk menyelesaikan persoalan tugas akhir. Tahapan studi literatur tidak perlu dituliskan karena ini adalah pekerjaan yang harus Anda lakukan selama proses pelaksanaan tugas akhir.
%
%\section{Sistematika Pembahasan}
%
%Subbab ini berisi penjelasan ringkas isi per bab. Penjelasan ditulis satu paragraf per bab buku.
