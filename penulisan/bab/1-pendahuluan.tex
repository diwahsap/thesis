\chapter{PENDAHULUAN}

\section{Latar Belakang}

Perusahaan dan organisasi menghasilkan dan menyimpan data dalam skala besar setiap hari dengan tingkat pertumbuhannya yang dinamis \cite{samadiPerformanceComparisonHadoop2018}. Pertumbuhan jumlah data diperkirakan akan meningkat hingga 5x lipat pada tahun 2025 dengan \textit{Global Datasphere} diproyeksikan tumbuh dari 33 \textit{Zettabytes} (ZB) pada tahun 2018 menjadi 175 ZB pada tahun 2025 \cite{reinselDigitizationWorldEdge2018}. Jumlah data tersebut membutuhkan pengolahan dengan kecepatan tinggi sehingga dapat dimanfaatkan untuk keperluan bisnis dan pengambilan keputusan \cite{adrianExpertReviewBig2018}. Sebagai contoh, analisis data transaksi nasabah pada perbankan dapat digunakan untuk mendeteksi kecurangan dan meningkatkan keamanan \cite{syahputraPendeteksianFraudPeran2020}, data pasien pada bidang kesehatan dapat memantau wabah penyakit dan menemukan pola pengobatan yang optimal \cite{sulaimanLITERATUREREVIEWPENERAPAN2023}, dan data interaksi pengguna pada \textit{e-commerce} diolah untuk memberikan rekomendasi produk personal dan merancang strategi peningkatan penjualan \cite{fernandoUtilizationBigData2020}. 

Data interaksi pengguna pada bidang \textit{e-commerce} dapat dianalisis dengan menerapkan algoritma \textit{sort} dan \textit{word count}, seperti \textit{term frequency-inverse document frequency} (TF-IDF) dan \textit{bag-of-words} (BoW) dimana akan menganalisis kata kunci yang sering muncul dalam deskripsi produk yang dilihat oleh pengguna, sistem dapat merekomendasikan produk serupa atau bahkan produk yang lebih relevan dengan preferensi pengguna tersebut \cite{shrivastavaProductRecommendationsUsing2019}.

Semakin besar data yang bisa ditangani, semakin banyak peluang analisis dan nilai yang bisa dihasilkan. Namun, semakin besar volume data yang harus diolah, semakin kompleks pula tantangan yang dihadapi dalam mengelolanya secara efisien dan efektif \cite{KOMPARASIKECEPATANHADOOP}. Tantangan utama dalam mengelola volume data yang besar adalah memastikan ketersediaan sumber daya komputasi yang memadai. Pendekatan konvensional pemrosesan data besar seperti menambah kapasitas penyimpanan pada perangkat komputasi yang sama dan penggunaan sistem basis data \textit{not only SQL} (NoSQL) memungkinkan pengolahan data menjadi \textit{scalable} dan fleksibel. Namun, ketika skala dan kompleksitas data semakin meningkat, komputasi terdistribusi menjadi pilihan yang lebih tepat karena memiliki sifat \textit{fault-tolerant}, yaitu kemampuan agar tetap beroperasi normal walaupun mengalami kegagalan sebagian dari sistemnya tersebut \cite{saadoonFaultToleranceBig2022}.

Pengolahan data besar yang melibatkan penerapan algoritma seperti \textit{sort} dan \textit{word count} apabila dijalankan secara serial akan memakan waktu pemrosesan yang lama, terutama dengan volume data yang besar. Oleh karena itu, solusi komputasi terdistribusi diperlukan untuk meningkatkan efisiensi dan kecepatan pemrosesan data. Dua teknologi yang umum digunakan dalam komputasi terdistribusi adalah Hadoop dan Spark \cite{saputroPerbandinganKinerjaKomputasi2020}. Hadoop dan Spark adalah \textit{platform} komputasi \textit{big data} yang populer dan banyak digunakan di seluruh dunia. Pada tahun 2027, Hadoop diperkirakan akan memiliki peningkatan \textit{market size} sebesar USD 341.4 miliar, dari USD 35.3 miliar pada tahun 2024 \cite{HadoopMarketSize}.

Hadoop dan Spark menawarkan berbagai kemampuan untuk mengelola, menyimpan, dan menganalisis data dalam skala besar. Hadoop dan Spark sama-sama memanfaatkan teknik MapReduce untuk memproses data secara terdistribusi \cite{deanMapReduceSimplifiedData2004}. MapReduce merupakan pendekatan yang  efektif dalam komputasi terdistribusi karena memungkinkan pemrosesan data yang besar dan kompleks dengan membagi tugas menjadi dua tahap utama, yaitu \textit{map} dan \textit{reduce}. Meskipun sama-sama menggunakan teknik MapReduce, Hadoop dan Spark memiliki skema implementasi yang berbeda. Hadoop menggunakan \textit{Hadoop Distributed File System} (HDFS) sebagai sistem penyimpanan data \cite{samadiComparativeStudyHadoop2016}, sementara Spark menggunakan \textit{Resilient Distributed Datasets} (RDDs) yang bersifat \textit{in-memory}. HDFS merupakan sistem penyimpanan berkas terdistribusi yang dirancang untuk menangani data dalam skala besar, sedangkan RDDs memungkinkan penyimpanan data secara sementara di memori, sehingga memungkinkan Spark untuk memproses data lebih cepat \cite{ahmadvandGapproxUsingGallup2019}. 

Perbedaan skema tersebut memungkinkan terdapat perbedaan performansi yang dihasilkan dari data yang diproses. Salah satu cara untuk membandingkan performa keduanya adalah menggunakan HiBench. HiBench adalah alat ukur yang dirancang khusus untuk mengukur kinerja sistem \textit{big data}, termasuk Hadoop dan Spark \cite{huangHiBenchBenchmarkSuitea}. HiBench memiliki \textit{benchmark} yang dirancang khusus untuk mengukur kinerja suatu algoritma seperti \textit{word count} dan \textit{sort} yang diimplementasikan pada sistem rekomendasi. HiBench juga dapat digunakan pada berbagai \textit{platform cloud}, termasuk DigitalOcean.

Penelitian ini bertujuan untuk mengevaluasi dan membandingkan kinerja Hadoop dan Spark pada \textit{platform cloud} DigitalOcean menggunakan HiBench. Fokus penelitian ini adalah pada beban kerja \textit{word count} dan \textit{sort}, yang mewakili tugas pemrosesan data yang umum. Dengan menganalisis waktu eksekusi, \textit{throughput}, dan penggunaan sumber daya (CPU, memori, I/O), penelitian ini bertujuan untuk memberikan wawasan tentang kekuatan dan kelemahan relatif dari Hadoop dan Spark dalam pemrosesan data. Temuan penelitian ini akan memberikan panduan bagi para praktisi dan peneliti di bidang \textit{big data} untuk memilih \textit{platform} yang tepat untuk kebutuhan pemrosesan data mereka.

\section{Rumusan Masalah}
Adapun rumusan masalah dalam penelitian ini adalah sebagai berikut:
\begin{enumerate}
\item Bagaimana performa Hadoop dan Spark dalam hal waktu eksekusi dan \textit{throughput} saat menjalankan beban kerja \textit{word count} dan \textit{sort} pada \textit{platform cloud} DigitalOcean?
\item Bagaimana pola penggunaan performa sumber daya (CPU, memori, I/O) oleh Hadoop dan Spark saat menjalankan beban kerja \textit{word count} dan \textit{sort} dengan berbagai ukuran data?
\end{enumerate}

\section{Tujuan}
Penelitian ini memiliki tujuan, yaitu:
\begin{enumerate}
\item Menganalisis dan membandingkan performa Hadoop dan Spark dalam hal waktu eksekusi dan \textit{throughput} saat menjalankan beban kerja \textit{word count} dan \textit{sort} pada \textit{platform cloud} DigitalOcean.
\item Mengidentifikasi pola performa penggunaan sumber daya (CPU, memori, I/O) oleh Hadoop dan Spark saat menjalankan beban kerja \textit{word count} dan \textit{sort} dengan berbagai ukuran data.
\end{enumerate}

%\section{Manfaat}
%Hasil dari penelitian ini diharapkan akan memberikan manfaat sebagai berikut:
%\begin{enumerate}
%	\item 
%	Penelitian ini akan memberikan informasi yang berguna bagi organisasi yang sedang mempertimbangkan pemilihan platform \textit{Big Data}, sehingga \textit{stakeholder} dapat membuat keputusan yang lebih terinformasi.	
%	\item
%	Penelitian ini akan membantu dalam memahami lebih dalam kinerja Hadoop dan Spark dalam berbagai skenario pemrosesan data.
%	\item
%	Hasil dari penelitian ini dapat menjadi dasar untuk penelitian lebih lanjut dalam pengembangan dan peningkatan platform \textit{Big Data.}
%\end{enumerate}

\section{Batasan Masalah}
Penelitian ini memiliki beberapa batasan yang perlu diperhatikan sebagai berikut:
	\begin{enumerate}
		\item Perfoma pada penelitian ini berdasarkan pada waktu eksekusi, \textit{throughput}, dan penggunaan sumber daya (CPU, memori, I/O).
		\item Penelitian ini akan fokus pada perbandingan kinerja antara Hadoop dan Spark dalam mode \textit{pseudo-distributed} dengan input data berupa teks.
		\item Pengukuran performa akan menggunakan HiBench (tolok ukur utama) dan Dool \textit{Monitoring System} (tolok ukur pembantu) 
		\item Implementasi Hadoop dan Spark akan menggunakan salah satu penyedia layanan awan, yaitu \textit{DigitalOcean}.
	\end{enumerate}

%\section{Metodologi}
%
%Tuliskan semua tahapan yang akan dilalui selama pelaksanaan tugas akhir. Tahapan ini spesifik untuk menyelesaikan persoalan tugas akhir. Tahapan studi literatur tidak perlu dituliskan karena ini adalah pekerjaan yang harus Anda lakukan selama proses pelaksanaan tugas akhir.
%
%\section{Sistematika Pembahasan}
%
%Subbab ini berisi penjelasan ringkas isi per bab. Penjelasan ditulis satu paragraf per bab buku.
